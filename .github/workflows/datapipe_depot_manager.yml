name: data-pipeline-depot-manager

on:
  workflow_dispatch:
  schedule:
    - cron: 15 7,8,9,10,11,12,13,14,15,16,17,18,19,20,21 * * 4,5 # every day every hour from 10 to 22, not on sunday as other runs run - crontab guru for more info

jobs:
  run-depot-manager:
    runs-on: ubuntu-latest # 1. create an ubuntu instance
    steps:
      - name: Checkout repo content # 2. pull all code from github repo
        uses: actions/checkout@v4 
        with: 
          token: ${{ secrets.ACCESS_TOKEN }} # give workflow read and write access  to repo 18:36
      - name: setup python # 3. create a python env
        uses: actions/setup-python@v5 
        with:
          python-version: '3.9'
          cache: 'pip' # pip libraries can be called from cache and don't have to be installed only once
      - name: install dependencies # 4. install the necessary libraries
        run: pip install -r requirements.txt
      - name: run depot manager # 5. run the python script
        run: python depot_mgt.py
      - name: check repo for changes # checking difference between staged changes and öast commits quiet: 0 when no changes true when changes
        id: git-check
        run: |           # checking difference between staged changes and öast commits quiet: 0 when no changes true when changes and set it as environmental variable (changes())
          git config user.name 'github-actions'
          git config user.email 'github-actions@gibthub.com'
          git add .
          git diff --staged --quiet || echo "changes=true" >> $GITHUB_ENV 
      - name: commit and push if changes # commit changes
        if: env.changes == 'true'
        run: |
          git commit -m "updated depot"
          git push